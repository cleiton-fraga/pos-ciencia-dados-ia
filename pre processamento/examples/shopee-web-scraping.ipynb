{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Shopee Web Scraping\\n\",\n",
    "    \"\\n\",\n",
    "    \"Objetivo: notebook demonstrativo para buscar produtos na Shopee, extrair campos principais e salvar em JSON.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Checklist:\\n\",\n",
    "    \"- [ ] Implementar funções: build_search_url, fetch_html, parse_products_from_dom, scrape_search, save_to_json\\n\",\n",
    "    \"- [ ] Exemplo de uso com `termo` e salvar em `pre processamento`\\n\",\n",
    "    \"- [ ] Notas sobre quando usar Selenium e limitações (conteúdo dinâmico / bloqueio)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Dependências básicas\\n\",\n",
    "    \"import re\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"from typing import List, Dict, Optional\\n\",\n",
    "    \"\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"from bs4 import BeautifulSoup\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Observação: para páginas que carregam conteúdo via JS, usar Selenium (opcional)\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from selenium import webdriver\\n\",\n",
    "    \"    from selenium.webdriver.chrome.options import Options as ChromeOptions\\n\",\n",
    "    \"except Exception:\\n\",\n",
    "    \"    webdriver = None\\n\",\n",
    "    \"    ChromeOptions = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"DEFAULT_HEADERS = {\\n\",\n",
    "    \"    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\\n\",\n",
    "    \"    'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',\\n\",\n",
    "    \"}\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Funções principais (contratos)\\n\",\n",
    "    \"- build_search_url(query, page) -> str\\n\",\n",
    "    \"- fetch_html(url, use_selenium=False, driver=None) -> str\\n\",\n",
    "    \"- parse_products_from_dom(html) -> List[dict]\\n\",\n",
    "    \"- scrape_search(query, max_pages, use_selenium=False) -> pandas.DataFrame (ou List[dict])\\n\",\n",
    "    \"- save_to_json(data, path) -> None\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def build_search_url(query: str, page: int = 0, region: str = 'br') -> str:\\n\",\n",
    "    \"    \\\"Montar URL de busca da Shopee (heurística).\\n\",\n",
    "    \"    page: número de página (0-index).\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if not query or not isinstance(query, str):\\n\",\n",
    "    \"        raise ValueError('query deve ser uma string não vazia')\\n\",\n",
    "    \"    # A Shopee usa diferentes domínios/paths por região; essa é uma heurística simples\\n\",\n",
    "    \"    q = query.strip().replace(' ', '+')\\n\",\n",
    "    \"    # Página em Shopee frequentemente usa um parâmetro de offset/next; manter simples: adicionar 'page' como query param\\n\",\n",
    "    \"    base = f'https://shopee.{region}/search?keyword={q}'\\n\",\n",
    "    \"    if page and int(page) > 0:\\n\",\n",
    "    \"        base = base + f'&page={int(page)}'\\n\",\n",
    "    \"    return base\\n\",\n",
    "    \"\\n\",\n",
    "    \"def fetch_html(url: str, use_selenium: bool = False, driver=None, timeout: int = 15, retries: int = 3, headers: Optional[dict] = None) -> str:\\n\",\n",
    "    \"    \\\"Faz requisição e retorna HTML. Se use_selenium=True usa o driver passado.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    headers = headers or DEFAULT_HEADERS\\n\",\n",
    "    \"    last_exc = None\\n\",\n",
    "    \"    for attempt in range(retries):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            if use_selenium:\\n\",\n",
    "    \"                if driver is None:\\n\",\n",
    "    \"                    raise RuntimeError('driver do Selenium não fornecido')\\n\",\n",
    "    \"                driver.get(url)\\n\",\n",
    "    \"                time.sleep(1)\\n\",\n",
    "    \"                return driver.page_source\\n\",\n",
    "    \"            resp = requests.get(url, headers=headers, timeout=timeout)\\n\",\n",
    "    \"            if resp.status_code in (429, 503):\\n\",\n",
    "    \"                time.sleep(1 + attempt * 2)\\n\",\n",
    "    \"                last_exc = RuntimeError(f'Status {resp.status_code}')\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"            resp.raise_for_status()\\n\",\n",
    "    \"            resp.encoding = resp.apparent_encoding or resp.encoding\\n\",\n",
    "    \"            return resp.text\\n\",\n",
    "    \"        except Exception as exc:\\n\",\n",
    "    \"            last_exc = exc\\n\",\n",
    "    \"            time.sleep(1 + attempt * 1.5)\\n\",\n",
    "    \"    raise RuntimeError(f'Falha ao buscar URL {url}: {last_exc}')\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _extract_number(s: str) -> Optional[float]:\\n\",\n",
    "    \"    if s is None:\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"    ss = re.sub(r\"[^0-9,\\.]\", '', str(s))\\n\",\n",
    "    \"    if not ss:\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"    # normalizar vírgula decimal\\n\",\n",
    "    \"    if ss.count(',') == 1 and ss.count('.') >= 1:\\n\",\n",
    "    \"        ss = ss.replace('.', '').replace(',', '.')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        ss = ss.replace(',', '.')\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        return float(ss)\\n\",\n",
    "    \"    except Exception:\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"def parse_products_from_dom(html: str) -> List[Dict]:\\n\",\n",
    "    \"    \\\"Tenta extrair produtos do HTML da Shopee usando heurísticas.\\n\",\n",
    "    \"    Retorna lista de dicionários com: TITLE, PRICE, URL, SHOP, RATING, SOLD, SCRAPE_DATETIME\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    soup = BeautifulSoup(html, 'html.parser')\\n\",\n",
    "    \"    results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # heurística 1: procurar por links de produtos (href contendo '/product/' ou '/item/')\\n\",\n",
    "    \"    anchors = soup.find_all('a', href=True)\\n\",\n",
    "    \"    product_links = []\\n\",\n",
    "    \"    for a in anchors:\\n\",\n",
    "    \"        href = a['href']\\n\",\n",
    "    \"        if re.search(r'(/product/|/item/|/product)', href):\\n\",\n",
    "    \"            product_links.append((a, href))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # fallback: procurar por blocos que pareçam cards (divs com imagens e títulos)\\n\",\n",
    "    \"    if not product_links:\\n\",\n",
    "    \"        cards = soup.select('div[data-sqe=\"item\"]') or soup.select('div._1gkBDw') or []\\n\",\n",
    "    \"        for c in cards:\\n\",\n",
    "    \"            a = c.find('a', href=True)\\n\",\n",
    "    \"            if a:\\n\",\n",
    "    \"                product_links.append((a, a['href']))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    seen = set()\\n\",\n",
    "    \"    for a, href in product_links:\\n\",\n",
    "    \"        # normaliza URL absoluta\\n\",\n",
    "    \"        url = href if href.startswith('http') else ('https://shopee.com' + href)\\n\",\n",
    "    \"        if url in seen:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        seen.add(url)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        title = (a.get('title') or a.get_text(strip=True) or a.find('img')['alt'] if a.find('img') else None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # procura price próximo ao link: procura no pai até alguns níveis\\n\",\n",
    "    \"        price = None\\n\",\n",
    "    \"        parent = a\\n\",\n",
    "    \"        for _ in range(4):\\n\",\n",
    "    \"            parent = parent.parent if parent and parent.parent else None\\n\",\n",
    "    \"            if parent is None:\\n\",\n",
    "    \"                break\\n\",\n",
    "    \"            # tenta seletor de preço comum\\n\",\n",
    "    \"            p_el = parent.select_one('div._1w9jLI._37ge-4') or parent.select_one('span._2fi0ux') or parent.select_one('span.shopee-price')\\n\",\n",
    "    \"            if p_el:\\n\",\n",
    "    \"                price = _extract_number(p_el.get_text(' ', strip=True))\\n\",\n",
    "    \"                break\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # tenta extrair loja, rating, sold com heurísticas próximas\\n\",\n",
    "    \"        shop = None\\n\",\n",
    "    \"        rating = None\\n\",\n",
    "    \"        sold = None\\n\",\n",
    "    \"        # procura em elementos do mesmo bloco por textes indicativos\\n\",\n",
    "    \"        block = a.parent\\n\",\n",
    "    \"        if block:\\n\",\n",
    "    \"            shop_el = block.select_one('div.shop-name, div._1w5s3I, span._3-IDaF')\\n\",\n",
    "    \"            if shop_el:\\n\",\n",
    "    \"                shop = shop_el.get_text(' ', strip=True)\\n\",\n",
    "    \"            rating_el = block.select_one('div.score, div._3Oj5_n') or block.find(text=re.compile(r'\\d+(?:[.,]\\d+)?\\s*★'))\\n\",\n",
    "    \"            if rating_el:\\n\",\n",
    "    \"                rtxt = rating_el.get_text(' ', strip=True) if hasattr(rating_el, 'get_text') else str(rating_el)\\n\",\n",
    "    \"                m = re.search(r'(\\d+[.,]?\\d*)', rtxt)\\n\",\n",
    "    \"                if m:\\n\",\n",
    "    \"                    rating = float(m.group(1).replace(',', '.'))\\n\",\n",
    "    \"            sold_el = block.find(text=re.compile(r'vendido|vendidos|sold', re.I))\\n\",\n",
    "    \"            if sold_el:\\n\",\n",
    "    \"                m = re.search(r'(\\d+[.,]?\\d*)', sold_el)\\n\",\n",
    "    \"                if m:\\n\",\n",
    "    \"                    sold = int(float(m.group(1).replace(',', '.')))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        results.append({\\n\",\n",
    "    \"            'TITLE': title,\\n\",\n",
    "    \"            'PRICE': price,\\n\",\n",
    "    \"            'URL': url,\\n\",\n",
    "    \"            'SHOP': shop,\\n\",\n",
    "    \"            'RATING': rating,\\n\",\n",
    "    \"            'SOLD': sold,\\n\",\n",
    "    \"            'SCRAPE_DATETIME': datetime.now().isoformat(),\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return results\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def scrape_search(query: str, max_pages: int = 1, delay: float = 1.0, use_selenium: bool = False, driver=None) -> List[Dict]:\\n\",\n",
    "    \"    \\\"Orquestra chamadas para buscar múltiplas páginas e parsear os cards.\\n\",\n",
    "    \"    Retorna lista de dicionários.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    all_items: List[Dict] = []\\n\",\n",
    "    \"    for page in range(max_pages):\\n\",\n",
    "    \"        url = build_search_url(query, page=page)\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            html = fetch_html(url, use_selenium=use_selenium, driver=driver)\\n\",\n",
    "    \"        except Exception as exc:\\n\",\n",
    "    \"            print(f'Erro ao buscar página {page}: {exc}')\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"        items = parse_products_from_dom(html)\\n\",\n",
    "    \"        if not items:\\n\",\n",
    "    \"            print(f'Nenhum item encontrado na página {page} (pode ser conteúdo dinâmico ou bloqueio)')\\n\",\n",
    "    \"        all_items.extend(items)\\n\",\n",
    "    \"        time.sleep(delay)\\n\",\n",
    "    \"    # deduplicar por URL\\n\",\n",
    "    \"    seen = set()\\n\",\n",
    "    \"    uniq = []\\n\",\n",
    "    \"    for it in all_items:\\n\",\n",
    "    \"        u = it.get('URL')\\n\",\n",
    "    \"        if u and u not in seen:\\n\",\n",
    "    \"            seen.add(u)\\n\",\n",
    "    \"            uniq.append(it)\\n\",\n",
    "    \"    return uniq\\n\",\n",
    "    \"\\n\",\n",
    "    \"def save_to_json(data: List[Dict], path: str) -> None:\\n\",\n",
    "    \"    os.makedirs(os.path.dirname(path), exist_ok=True)\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # pandas not required; use json safe dump\\n\",\n",
    "    \"        with open(path, 'w', encoding='utf-8') as fh:\\n\",\n",
    "    \"            json.dump(data, fh, ensure_ascii=False, indent=2)\\n\",\n",
    "    \"        print(f'Saved {len(data)} records to {os.path.abspath(path)}')\\n\",\n",
    "    \"    except Exception as exc:\\n\",\n",
    "    \"        raise\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Exemplo de uso\\n\",\n",
    "    \"Coloque o exemplo em `if False` para evitar execução automática ao abrir o notebook. Ajuste `termo` e `max_pages` antes de executar.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if False:\\n\",\n",
    "    \"    termo = 'celular'\\n\",\n",
    "    \"    items = scrape_search(termo, max_pages=2, delay=2.0, use_selenium=False)\\n\",\n",
    "    \"    out_path = os.path.join('pre processamento', f'shopee_{termo}.json')\\n\",\n",
    "    \"    save_to_json(items, out_path)\\n\",\n",
    "    \"    # mostrar alguns registros\\n\",\n",
    "    \"    print(items[:5])\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Notas finais e recomendações\\n\",\n",
    "    \"- A Shopee usa carregamento dinâmico em muitas páginas; se `parse_products_from_dom` não encontrar itens, tente `use_selenium=True` com um driver Chrome/Firefox headless.\\n\",\n",
    "    \"- Respeite robots.txt e políticas da plataforma.\\n\",\n",
    "    \"- Para robustez: adicionar proxy rotativo, user-agent rotativo e backoff exponencial.\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "e1e6cb584bd3998f"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
